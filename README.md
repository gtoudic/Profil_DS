# üëã Bonjour, je suis Gwenn !

## üîß Comp√©tences en Data Science

- **Comp√©tences en statistique** : 
  - Statistiques descriptives
  - Mod√©lisation pr√©dictive
  - **Machine Learning**, Deep Learning, NLP, Computer Vision

- **Comp√©tences techniques** :  
   **Python** (Pandas, Scikit Learn, TensorFlow, Keras, Hugging Face)
   **SQL**
   SAS
   JupyterLab, Google Colaboratory, Visual Studio Code
   **Git**, GitHub
   **Cloud** (Azure, AWS)
   FastApi, Streamlit, Docker, MLflow, GitHub Actions
   **Spark**, Hadoop 
   Linux
   Power BI
   Excel

## üíº Projets professionnels r√©alis√©s en 2024 - formation Data Scientist OpenClassrooms 

### Projet 4 **Anticipez les besoins en consommation de b√¢timents**
   - Explorer et pr√©parer les donn√©es √† la mod√©lisation ; cr√©er des variables pertinentes (feature engineering)
   - Mettre en place une d√©marche it√©rative de Machine Learning
   - Cr√©er, entra√Æner et √©valuer des mod√®les d'apprentissage supervis√© (R√©gression Lin√©aire, ElasticNet, SVM, Arbre de d√©cision, Random Forest, Gradient Boosting) avec Scikit learn
   - Comparer les performances des diff√©rents algorithmes
   - Optimiser avec GridSearchCV
   - Expliquer le mod√®le pr√©dictif retenu ; analyser la feature importance globale et locale

### Projet 5 **Segmentez des clients d'un site e-commerce**
   - Mener une analyse exploratoire en utilisant SQL (SQLite)
   - Etablir des points de r√©f√©rence R√©cence Fr√©quence Montant (segmentation bas√©e sur des r√®gles simples)
   - Effectuer le feature engineering sur des datasets multiples pour pr√©parer la mod√©lisation Machine Learning
   - Entra√Æner des mod√®les d‚Äôapprentissage non-supervis√© (algorithmes KMeans et DBScan, approche CAH) et √©valuer leurs performances
   - Interpr√©ter les segments du clustering optimal (visualisation, naming, description) et analyser leur stabilit√©
   - Simuler un contrat de maintenance

### Projet 6 **Classifiez automatiquement des biens de consommation**
   - Automatiser la classification d'articles en cat√©gories, √† partir de donn√©es textuelles et visuelles
   - Machine Learning / Deep Learning pour mod√©liser des donn√©es non-structur√©es
   - Natural Language Processing (NLP) avec NLTK, Tokenisation, Bag of Words, TF-IDF, Word2Vec, BERT et USE (HuggingFace)
   - Computer Vision avec OpenCV, algorithme SIFT et par Transfer Learning sur mod√®le CNN VGG-16 (TensorFlow / Keras), data augmentation
   - R√©ductions dimensionnelles PCA et t-SNE
   - Clustering k-means
   - Analyse des performances ; mesure de comparaison par le calcul de l‚ÄôARI (Adjusted Rand Index) entre les cat√©gories r√©elles et les clusters
   - Stack technique : JupyterLab

### Projet 7 **Impl√©mentez un scoring cr√©dit et r√©alisez un dashboard**
   - Construire un mod√®le de scoring qui donnera une pr√©diction sur la probabilit√© de faillite d'un client de fa√ßon automatique
   - Analyser les features qui contribuent le plus au mod√®le, d‚Äôune mani√®re g√©n√©rale (feature importance globale) et au niveau d‚Äôun client (feature importance locale)
   - Mettre en production le mod√®le de scoring de pr√©diction √† l‚Äôaide d‚Äôune API et r√©aliser une interface de test de cette API
   - Mettre en ≈ìuvre une approche globale MLOps de bout en bout, du tracking des exp√©rimentations √† l‚Äôanalyse en production du data drift
   - D√©marche MLOps : BUILT TEST DEPLOY
      API de pr√©diction (FastApi)
      Git & GitHub pour versioning de code et int√©gration continue
      Docker, services container registery et web app du cloud Azure et GitHub Actions pour le d√©ploiement continu et automatis√© (CI/CD)
      Tests unitaires (PyTest)
      Interface utilisateur graphique (dashboard Streamlit)
      Ind√©pendance back end et front end
      Data Drift (Evidently)
   - Stack technique : VSCode | GitHub | MLflow | FastAPI | Microsoft Azure | PyTest | Docker | Streamlit
   - **Lien vers le Projet** : [Voir sur GitHub](https://github.com/gtoudic/OCP7creditscoring)

### Projet 8 **Assurez une veille technique**
   - R√©aliser une veille technique sur le traitement de donn√©es texte et une preuve de concept (POC) en la mettant en ≈ìuvre sur une probl√©matique abord√©e dans un projet pr√©c√©dent : Large Language Model (LLM), architecture Transformers, LLaMA3
   - Comparer la performance avec les autres m√©thodes utilis√©es, plus traditionnelles
   - Restituer une note m√©thodologique et pr√©senter le travail de veille
   - Stack technique : Google Colaboratory

### Projet 9 **R√©alisez un traitement de donn√©es dans un environnement Big Data sur le Cloud**
   - Mettre en place une architecture Big Data : s√©lectionner les outils du Cloud permettant de traiter et stocker des donn√©es massives (Hadoop, AWS S3, EMR et IAM, tunnel SSH, PySpark, JupyterHub, Spark Web UI)
   - Mod√©liser des donn√©es dans un environnement Big Data (passage √† l'√©chelle)
   - R√©aliser des calculs distribu√©s
   - Stack technique : Spark | AWS | Linux | JupyterHub

### Projet 10 **Cadrez un projet IA**
   - Mettre en place la m√©thode de gestion de projet agile Scrum : √©laborer un product backlog et un planning des sprints, dimensionner le projet (√©quipe/comp√©tences, co√ªts, notamment l'infrastructure Azure)
   -Estimer les gains attendus et la rentabilit√©
   -G√©rer les risques et les enjeux l√©gaux et √©thiques li√©s aux donn√©es personnelles et √† l'Intelligence Artificielle : identifier, √©valuer la criticit√© et mitiger les risques du projet



